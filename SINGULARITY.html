<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manifesto</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: flex-start; /* Align content to the top */
            min-height: 100vh; /* Ensure body covers the full viewport height */
            background-color: #f0f0f0; /* Light background color for contrast */
        }
        .container {
            width: 60%; /* Control width */
            max-width: 900px; /* Set a max width for larger screens */
            min-width: 300px; /* Prevent it from getting too narrow on small screens */
            background-color: #ffffff;
            padding: 40px;
            margin: 20px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1); /* Subtle shadow for depth */
            border-radius: 8px; /* Rounded corners */
            line-height: 1.6; /* Line height for readability */
        }
        h1 {
            text-align: center;
            margin-bottom: 40px;
        }
        h2, h3 {
            margin-top: 40px;
        }
        p, ul {
            margin-bottom: 20px;
        }
        .sidebar {
            font-size: 14px;
            color: #555;
            margin-top: 40px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>staring into the singularity: a reflection</h1>

        <h2>INTRO</h2>
        <p> With my limited knowledge of science, engineering, mathematics and statistics, I want to think 
            about the singularity. Why do I want to think about it? Because I think that thinking about the 
            Singularity and ways of reaching the singularity or discussing if the singularity is possible 
            allows us to dissect ourselves and the way we have constructed reality. The singularity requires 
            the construction of general intelligence but what is intelligence and what does it tell us about 
            the nature of our reality? These are ideas that I always want to think about and in my opinion 
            inform my decision making in various unobvious ways. Anyways the singularity. </p>
    
        <p> I'm reading the staring into the singularity from a blog post by Eliezer Yudkowsky, a self taught American 
            computer scientist and researcher. I found this blog post here:
        </p>
    
        <a href="http://www.fairpoint.net/~jpierce/staring_into_the_singularity.htm">the staring into the singularity</a>



        <h2>THE SHORT VERSION</h2>
        <blockquote>"If computing power doubles every two years, what happens when computers are doing the research?

            <br>

            Computing power doubles every two years. 
            
            <br>

            Computing power doubles every two years of work. 
            
            <br>

            Computing power doubles every two *subjective* years of work.
            
            <br>

            Two years after computers reach human equivalence, their power doubles again. *One* year later, their speed doubles again.
            
            <br>

            Six months - three months - 1.5 months ... Singularity.
            
            <br>

            It's expected in 2035. (Oops, make that 2025.)"
        </blockquote>
    
            <p>What does “subjective” years of work mean? 

                <br>
                <br>
                I think that when we have adaptive, intelligent systems such as ourselves, that we evolved for survival and moving 
                physically first. Movement, walking, ways to acquire food, ways to digest food. And once we “figured out” a way to 
                do these thing, we have some free energy in our system to be used to further make ourselves more efficient and 
                “surviving”. This is purely speculative, I could go into more detail and research to back my hypothesis (on free energy) 
                 but I will leave that for another time. What I’m trying to get at here is that as a system, I believe we have 
                 exhausted our physical efficiency. When we are the most efficient at acquiring food, water and shelter, what’s 
                 next? I believe it is our conceptual world. We have complex abstractions of the physical world that inform our 
                 way of life. For example, we call all have shelter, so then we can have different aesthetics and organizations of
                  houses that can be looked at from a cultural or social standpoint, these are the abstractions of something physical,
                   that purely exist in a subjective space.
    
            </p>
            <p>What is this subjective space? I think its what we call subjective intelligence. I don’t believe there is any concrete 
                theory or definition of intelligence from what I have read so far, but I believe intelligence to be the ability for 
                a system to classify data (inputs) into binary categories without the indication of what the two groups are. I will go 
                more into detail about this at some other time, but It is evident to me that with subjective work this is what we are 
                talking about, when we say being intelligent. 
    
            </p>
            <p>I’m also not entirely sure I understand what an entity that is more subjective than me looks like. What will that 
                system that is more intelligent and subjective than me think about the world, or relationships, or anything really. 
                What will it be incentivized to think about?
    
            </p>
            <h2>THE END OF HISTORY</h2>
            <p> Here are graphs based on the writing. The idea is that it should be like exponential decay of time, or something 
                similar to that. Like the time it takes to move to the next stage, is halved. Again its not exactly like that but 
                I like looking at graphs </p>
                <img src="Figure_1.png" alt="Timeline of Key events" width="600" height="400">
                <img src="Figure_2.png" alt="Timeline of Key events but with logs" width="600" height="400">

                <blockquote>"someone will come up with a method of increasing the maximum intelligence on the planet either coding a 
                    true Artificial Intelligence or enhancing human intelligence. An enhanced human would be better at thinking up ways 
                    of enhancing humans; he would have an 'increased capacity for invention'”
                </blockquote>
        
            <p> For some reason this feels wrong. I think humans right now are relatively intelligent but I don't see how we have used out 
                intelligence to make intelligence just for the sake of making more intelligent systems. Something tells me that we should have 
                made it already, because I think we are already pretty intelligent. 
            </p>
            <p> Also if I use my definition of intelligence (binary classification) then I see that there is an extremely large number of ways 
                to classify the data we get, but there is a finite limit unless we increase the levels of abstraction. For example, take houses. 
                Maybe in our early stages of evolution you either had shelter or no shelter. But now we have various different types of structures. 
                They are ordered and they have a social and even cultural connotations. We are more intelligent than our ancestors during that time. 
                But can we predict the next level of abstraction? I’m not sure about that. Is there an upper limit to the number of abstractions? 
                I'm not sure either. Maybe we won’t even be able to understand a machine or human that has more levels of abstractions then us. 
            </p>
            <p> Another question is how can we learn how abstractions are created. I think this might be a consequence of free energy in a system 
                but I have no proof of this yet. So maybe the next level of abstractions is the ability for a system to make more efficient better 
                abstractions? For some reason I feel like I’m talking in circles here.
            </p>
    
    
    </div>
</body>
</html>
